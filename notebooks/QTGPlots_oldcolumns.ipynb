{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import networkit as nk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import rcParams\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten (l):\n",
    "    result = []\n",
    "    for s in l:\n",
    "        for el in s:\n",
    "            result.append(el)\n",
    "    return result\n",
    "\n",
    "def shorten(name):\n",
    "    return name.lstrip('cost_matrix_component_nr_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMean(df, res):\n",
    "    result_set = df[res].values\n",
    "    if (len(result_set) == 0):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return sum(result_set) / len(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEffect(df, b, res, b_v, percentual):\n",
    "    ref = defaults[b]\n",
    "    on = getMean(df.loc[(df[b] == b_v)], res)\n",
    "    off = getMean(df.loc[(df[b] == ref)], res)\n",
    "    if percentual:\n",
    "        return (1 - (on/off)) * 100\n",
    "    else:    \n",
    "        return off - on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgEffect(df, a, b, res, b_v, percentual):\n",
    "    values = list(set(df[a].tolist()))\n",
    "    effect_sum = 0\n",
    "    for a_v in values:\n",
    "        effect_sum = effect_sum + getEffect(df.loc[(df[a] == a_v)], b, res, b_v, percentual)\n",
    "    return effect_sum / len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTex(output_df, table_name, title):\n",
    "    output_df = output_df.reset_index()\n",
    "    title = title.replace('_', '\\_')\n",
    "    print(title)\n",
    "    print(output_df)\n",
    "    output_file.write(title)\n",
    "    output_file.write('\\\\\\\\\\n')\n",
    "    output_file.write('Fixing ')\n",
    "    for (column, values) in fixed.items():\n",
    "        output_file.write(column + ' = ' + str(values).replace('[', '\\lbrack ').replace(']', '\\\\rbrack\\ ').replace('_', '\\_'))\n",
    "    output_file.write('\\\\\\\\\\n')\n",
    "    output_df.to_latex(tex_dir + table_name +'.tex', index=False)\n",
    "    output_file.write('\\input{./' + table_name + '.tex}\\n')\n",
    "    output_file.write('\\\\\\\\ \\\\\\\\\\n')\n",
    "    \n",
    "def writePlotTex(plt, name):\n",
    "    plt.savefig(plot_dir + name, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    output_file.write('\\includegraphics[width=\\\\textwidth]{../plots/' + name + '}\\n')\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOverview(df, exp, res, average = False, effect = False, percentual = False):\n",
    "    table_name = str(exp[len(exp) - 1]) + '_' + res + '_table'\n",
    "    title = ''\n",
    "    if average:\n",
    "        table_name += '_avg'\n",
    "        effect = True\n",
    "    if effect:\n",
    "        table_name += '_effect'\n",
    "    if percentual:\n",
    "        table_name += '_percentual'\n",
    "    table_name +=  '_' + str(len(exp))\n",
    "        \n",
    "    if effect:\n",
    "        if average:\n",
    "            if percentual:\n",
    "                title = 'Average percentual effect '\n",
    "            else:\n",
    "                title = 'Average effect '\n",
    "        else:\n",
    "            if percentual:\n",
    "                title = 'Percentual effect '\n",
    "            else:\n",
    "                title = 'Effect '\n",
    "        title += 'of ' + str(exp[len(exp) - 1]) + ' on ' + res\n",
    "    else:\n",
    "        title = res + ' depending on ' + str(exp[len(exp) - 1])\n",
    "\n",
    "    if average:\n",
    "        if(exp[0] == 'graph'):\n",
    "            values = [[graph_set]]\n",
    "        else:\n",
    "            values =[['']]\n",
    "        values += [list(set(df[exp[i]].tolist())) for i in range(1, len(exp))]\n",
    "    else:\n",
    "        values = [list(set(df[e].tolist())) for e in exp]\n",
    "    \n",
    "    if effect:\n",
    "        values[len(exp) - 1].remove(defaults[exp[len(exp) - 1]])\n",
    "    data_rows = []\n",
    "    if(len(exp) == 2):\n",
    "        for e0 in values[0]:\n",
    "            data_row = []\n",
    "            for e1 in values[1]:\n",
    "                if(average):\n",
    "                    data_row.append(getAvgEffect(df, exp[0], exp[1], res, e1, percentual))\n",
    "                else:\n",
    "                    if(effect):\n",
    "                        data_row.append(getEffect(df.loc[(df[exp[0]] == e0)], exp[1], res, e1, percentual))\n",
    "                    else:\n",
    "                        data_row.append(getMean(df.loc[(df[exp[0]] == e0) & (df[exp[1]] == e1)], res))\n",
    "            data_rows.append(np.array(data_row))\n",
    "        output_df = pd.DataFrame(data_rows, index=values[0], columns=values[1])\n",
    "        if (not average) and (exp[0] == 'graph'):\n",
    "            node_counts = [df.loc[df['graph'] == g]['n'].values[0] for g in values[0]]\n",
    "            output_df.insert(0, column='n', value=node_counts)\n",
    "\n",
    "    if(len(exp) == 3):\n",
    "        for e0 in values[0]:\n",
    "            for e1 in values[1]:\n",
    "                data_row = []\n",
    "                for e2 in values[2]:\n",
    "                    if(average):\n",
    "                        data_row.append(getAvgEffect(df.loc[(df[exp[1]] == e1)], exp[0], exp[2], res, e2, percentual))\n",
    "                    else:\n",
    "                        if(effect):\n",
    "                            data_row.append(getEffect(df.loc[(df[exp[0]] == e0) & (df[exp[1]] == e1)], exp[2], res, e2, percentual))\n",
    "                        else:\n",
    "                            data_row.append(getMean(df.loc[(df[exp[0]] == e0) & (df[exp[1]] == e1) & (df[exp[2]] == e2)], res))\n",
    "                data_rows.append(np.array(data_row))\n",
    "        row_headers = [np.array(flatten([[e0 for e1 in values[1]] for e0 in values[0]])), \n",
    "                    np.array(flatten([[e1 for e1 in values[1]] for e0 in values[0]]))]\n",
    "        output_df = pd.DataFrame(data_rows, index=row_headers, columns=values[2])\n",
    "        output_df.index = output_df.index.set_names([exp[0], exp[1]])\n",
    "        if (not average) and (exp[0] == 'graph'):\n",
    "            node_counts = [df.loc[df['graph'] == g]['n'].values[0] for g in output_df.index.get_level_values('graph')]\n",
    "            output_df.insert(0, column='n', value=node_counts)\n",
    "        \n",
    "    if(len(exp) == 4):\n",
    "        for e0 in values[0]:\n",
    "            for e1 in values[1]:\n",
    "                data_row = []\n",
    "                for e2 in values[2]:\n",
    "                    for e3 in values[3]:\n",
    "                        if(average):\n",
    "                            data_row.append(getAvgEffect(df.loc[(df[exp[1]] == e1) & (df[exp[2]] == e2)], exp[0], exp[3], res, e3, percentual))\n",
    "                        else:\n",
    "                            if(effect):\n",
    "                                data_row.append(getEffect(df.loc[(df[exp[0]] == e0) & (df[exp[1]] == e1) & (df[exp[2]] == e2)], exp[3], res, e3, percentual))\n",
    "                            else:\n",
    "                                data_row.append(getMean(df.loc[(df[exp[0]] == e0) & (df[exp[1]] == e1) & (df[exp[2]] == e2) & (df[exp[3]] == e3)], res))\n",
    "                data_rows.append(np.array(data_row))\n",
    "        row_headers = [np.array(flatten([[e0 for e1 in values[1]] for e0 in values[0]])), \n",
    "                    np.array(flatten([[e1 for e1 in values[1]] for e0 in values[0]]))]\n",
    "        columns = np.array(flatten([[[e2, e3] for e3 in values[3]] for e2 in values[2]]))\n",
    "        output_df = pd.DataFrame(data_rows, index=row_headers, columns=columns)\n",
    "        output_df.index = output_df.index.set_names([exp[0], exp[1]])\n",
    "        \n",
    "    output_df = output_df.round(2)   \n",
    "    writeTex(output_df, table_name, title)\n",
    "    return table_name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(scenario, fixed):\n",
    "    df = dfs[scenario]\n",
    "    for column, values in fixed.items():\n",
    "        possible_dfs = []\n",
    "        for value in values:\n",
    "            possible_dfs.append(df.loc[(df[column] == value)])\n",
    "        df = pd.concat(possible_dfs)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp[0] das wird gezählt (graphen)\n",
    "#exp[1] hierfür jeweils ein diagramm \n",
    "#exp[2] hierfür jeweils eine Linie (initializations)\n",
    "#exp[3] wenn definiert wird effekt des ersten untersucht\n",
    "def percentualPlot(df, exp, res):\n",
    "    values = [list(set(df[e].tolist())) for e in exp]\n",
    "    values[len(exp) - 1].remove(defaults[exp[len(exp) - 1]])\n",
    "    if(len(exp) == 4):\n",
    "        for e1 in values[1]:\n",
    "            fig, ax = plt.subplots()\n",
    "            min_p = 0\n",
    "            max_p = 0\n",
    "            for e2 in values[2]:\n",
    "                p = [getEffect(df.loc[(df[exp[0]] == e0) & (df[exp[1]] == e1) & (df[exp[2]] == e2)], exp[3], res, values[3][0], True) for e0 in values[0]]\n",
    "                p.sort(reverse = True)\n",
    "                plt.plot([((i+1) / len(p)) * 100 for i in range(len(p))], p, label = e2)\n",
    "                if p[0] > max_p:\n",
    "                    max_p = p[0]\n",
    "                if p[len(p) - 1] < min_p:\n",
    "                    min_p = p[len(p) - 1]\n",
    "            plt.ylabel(\"minimum percentual effect\")\n",
    "            plt.xlabel(\"% instances\")\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), frameon=True, ncol=len(values[2]))\n",
    "            ax.set_ylim(max_p * 1.1, min_p * 1.1)\n",
    "            plt.title('Percentual effect of ' + exp[2] +  ' on ' + res + ', ' + exp[1] + \"=\" + str(e1))\n",
    "            writePlotTex(plt, res + '_' + exp[3] + '_' + exp[2] + '_' + exp[1] + '_'+ str(e1) + '_percentual.png')\n",
    "            plt.show()\n",
    "    if(len(exp) == 3):\n",
    "        for e1 in values[1]:\n",
    "            fig, ax = plt.subplots()\n",
    "            min_p = 0\n",
    "            max_p = 0\n",
    "            for e2 in values[2]:\n",
    "                p = [getEffect(df.loc[(df[exp[0]] == e0) & (df[exp[1]] == e1)], exp[2], res, e2, True) for e0 in values[0]]\n",
    "                p.sort(reverse = True)\n",
    "                plt.plot([((i+1) / len(p)) * 100 for i in range(len(p))], p, label = e2)\n",
    "                if p[0] > max_p:\n",
    "                    max_p = p[0]\n",
    "                if p[len(p) - 1] < min_p:\n",
    "                    min_p = p[len(p) - 1]\n",
    "                    plt.xlabel('n')\n",
    "            plt.ylabel(\"minimum percentual effect\")\n",
    "            plt.xlabel(\"% instances\")\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), frameon=True, ncol=len(values[2]))\n",
    "            ax.set_ylim(max_p * 1.1, min_p * 1.1)\n",
    "            plt.title('Percentual effect of ' + exp[2] +  ' on ' + res + ', ' + exp[1] + \"=\" + str(e1))\n",
    "            writePlotTex(plt, res + '_' + exp[2] + '_' + exp[1] + '_'+ str(e1) + '_percentual.png')\n",
    "    if(len(exp) == 2):\n",
    "        fig, ax = plt.subplots()\n",
    "        min_p = 0\n",
    "        max_p = 0\n",
    "        for e1 in values[1]:\n",
    "            p = [getEffect(df.loc[(df[exp[0]] == e0)], exp[1], res, e1, True) for e0 in values[0]]\n",
    "            p.sort(reverse = True)\n",
    "            plt.plot([((i+1) / len(p)) * 100 for i in range(len(p))], p, label = e1)\n",
    "            if p[0] > max_p:\n",
    "                max_p = p[0]\n",
    "            if p[len(p) - 1] < min_p:\n",
    "                min_p = p[len(p) - 1]\n",
    "        plt.ylabel(\"minimum percentual effect\")\n",
    "        plt.xlabel(\"% instances\")\n",
    "        ax.set_ylim(max_p * 1.1, min_p * 1.1)\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), frameon=True, ncol=len(values[1]))\n",
    "        plt.title('Percentual effect of ' + exp[1] + ' on ' + res)\n",
    "        writePlotTex(plt , res + '_' + exp[2] + '_percentual.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentualOptimumPlot(df, exp, res):\n",
    "    values = [list(set(df[e].tolist())) for e in exp]\n",
    "    graphs = list(set(df['graph'].tolist()))\n",
    "    if(len(exp) == 2):\n",
    "        for e0 in values[0]:\n",
    "            fig, ax = plt.subplots()\n",
    "            min_p = 0\n",
    "            max_p = 0\n",
    "            for e1 in values[1]:\n",
    "                p = [df.loc[(df[exp[0]] == e0) & (df[exp[1]] == e1) & (df['graph'] == graph)]['optimum_delta_percentual'].values[0] for graph in graphs]\n",
    "                p.sort()\n",
    "                plt.plot([((i+1) / len(p)) * 100 for i in range(len(p))], p, label = e1)\n",
    "                if p[0] > max_p:\n",
    "                    max_p = p[0]\n",
    "                if p[len(p) - 1] < min_p:\n",
    "                    min_p = p[len(p) - 1]\n",
    "                    plt.xlabel('n')\n",
    "            plt.ylabel(\"maximum percent. distance to optimum\")\n",
    "            plt.xlabel(\"% instances\")\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), frameon=True, ncol=len(values[1]))\n",
    "            #ax.set_ylim(max_p * 1.1, min_p * 1.1)\n",
    "            plt.title('Percentual distance of ' + res + ' to optimum, depending on ' + exp[1]+ \", \" + exp[0] + \" = \" + str(e0))\n",
    "            writePlotTex(plt, res + '_' + exp[1] + '_' + exp[0] + '_'+ str(e0) + '_optimum_percentual.png')\n",
    "    if(len(exp) == 1):\n",
    "        fig, ax = plt.subplots()\n",
    "        min_p = 0\n",
    "        max_p = 0\n",
    "        for e0 in values[0]:\n",
    "            p = [df.loc[(df[exp[0]] == e0) & (df['graph'] == graph)]['optimum_delta_percentual'].values[0] for graph in graphs]\n",
    "            p.sort(reverse = True)\n",
    "            plt.plot([((i+1) / len(p)) * 100 for i in range(len(p))], p, label = e0)\n",
    "            if p[0] > max_p:\n",
    "                max_p = p[0]\n",
    "            if p[len(p) - 1] < min_p:\n",
    "                min_p = p[len(p) - 1]\n",
    "        plt.ylabel(\"maximum percent. distance to optimum\")\n",
    "        plt.xlabel(\"% instances\")\n",
    "        ax.set_ylim(max_p * 1.1, min_p * 1.1)\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), frameon=True, ncol=len(values[0]))\n",
    "        plt.title('Percentual distance of ' + res + ' to optimum, depending on ' + exp[0])\n",
    "        writePlotTex(plt , res + '_' + exp[2] + '_optimum_percentual.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterPlot(df, exp, res):\n",
    "    markers = [\".\", \"+\", \"^\", \"*\", \"s\", \"p\", \"P\"]\n",
    "    graphs = list(set(df['graph'].tolist()))\n",
    "    x = [getMean(df.loc[(df['graph'] == graph)], 'n') for graph in graphs]\n",
    "    if len(exp) == 1:\n",
    "        points = [getMean(df.loc[(df['graph'] == graph)], res) for graph in graphs]\n",
    "        plt.scatter(x, points)\n",
    "        plt.title(res + ' depending on number of nodes')\n",
    "        fig, ax = plt.subplots()\n",
    "        name = 'scatterplot_' + res\n",
    "        ax.set_xscale('log')\n",
    "        plt.xlabel('n')\n",
    "        plt.ylabel(res)\n",
    "        writePlotTex(plt, name)\n",
    "    if len(exp) == 2:\n",
    "        values = list(set(df[exp[1]].tolist()))\n",
    "        i = 0\n",
    "        colors = cm.rainbow(np.linspace(0, 1, len(values)))\n",
    "        name = 'scatterplot_' + res\n",
    "        fig, ax = plt.subplots()\n",
    "        for v in values:\n",
    "            plt.title(res + ' depending on number of nodes, for ' + exp[1] + ' = ' + v)\n",
    "            points = [getMean(df.loc[(df['graph'] == graph) & (df[exp[1]] == v)], res) for graph in graphs]\n",
    "            plt.scatter(x, points, color = colors[i], marker = markers[i], label = v, s=5)\n",
    "            i += 1\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), frameon=True, ncol=len(values))\n",
    "        plt.xlabel('n')\n",
    "        plt.ylabel(res)\n",
    "        ax.set_xlim(left=pow(10, math.log(df['n'].min(), 10)))\n",
    "        ax.set_xscale('log')\n",
    "        writePlotTex(plt, name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initTableCnt(df, usingOptima):\n",
    "    iters = list(set(df['maxIterations'].tolist()))\n",
    "    inits = list(set(df['initialization'].tolist()))\n",
    "    graphs = list(set(df['graph'].tolist()))\n",
    "    output_df = pd.DataFrame(columns=['it']+inits)\n",
    "    best = dict((i, [0 for i in range(len(inits))]) for i in iters)\n",
    "    best_vals = {}\n",
    "    for graph in graphs:\n",
    "        df_dict = dict((i, df.loc[(df['graph'] == graph) &  (df['maxIterations'] == i)]) for i in iters)\n",
    "        if usingOptima:\n",
    "            if graph in optima:\n",
    "                best_vals = dict((i, optima[graph]) for i in iters)\n",
    "            else:\n",
    "                best_vals = dict((i, np.nan) for i in iters)\n",
    "        else:\n",
    "            best_vals = dict((i, min(df_dict[i]['edits_mean'].values)) for i in iters)\n",
    "        for j in range(len(inits)):\n",
    "            init = inits[j]\n",
    "            for i in iters:\n",
    "                if(getMean(df_dict[i].loc[(df_dict[i]['initialization'] == init)], 'edits_mean') == best_vals[i]):\n",
    "                    best[i][j] = best[i][j] + 1\n",
    "    for i in range(len(iters)):\n",
    "        it = iters[i]\n",
    "        output_df.loc[i] = [it] + best[it]\n",
    "    output_df.reset_index(drop=True, inplace=True)\n",
    "    if usingOptima:\n",
    "        writeTex(output_df, 'init_table_opt', 'Number of graphs for which the initialization strategies ' + \n",
    "             'lead to the optimum (if known)')\n",
    "    else:\n",
    "        writeTex(output_df, 'init_table_best', 'Number of graphs for which the initialization strategies ' + \n",
    "             'lead to the minimum number of achieved edits_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(g):\n",
    "    global graph_set\n",
    "    graph_set = g\n",
    "    global inf_iterations\n",
    "    inf_iterations = 100\n",
    "    global plot_dir\n",
    "    plot_dir = '../output/QTM_gpute2/' + graph_set + '/plots/'\n",
    "    global tex_dir\n",
    "    tex_dir = '../output/QTM_gpute2/' + graph_set + '/tex/'\n",
    "    data_path = '../output/QTM_gpute2/' + graph_set + '/'\n",
    "    \n",
    "    if not os.path.exists(plot_dir):\n",
    "        os.makedirs(plot_dir)\n",
    "    if not os.path.exists(tex_dir):\n",
    "        os.makedirs(tex_dir)\n",
    "        \n",
    "    \n",
    "    global dfs\n",
    "    dfs = {'full' : pd.read_csv(data_path  + '/full.csv'), \n",
    "           'plateauBound' : pd.read_csv(data_path  + '/plateauBound.csv')}\n",
    "    \n",
    "    global defaults\n",
    "    defaults= {'initialization': 'trivial',\n",
    "              'randomness': False,\n",
    "              'sortPaths' : False,\n",
    "              'plateauSize' : 1,\n",
    "               'maxIterations' : 5}\n",
    "    \n",
    "    global optima\n",
    "    optima = {'karate' : 21, 'lesmis' : 60, 'dolphins' : 72}\n",
    "    bio_df = pd.read_csv('../input/biological/bio_data.csv')\n",
    "    for index, row in bio_df.iterrows():\n",
    "        optima[shorten(row['Graph'].split('.')[0])] = int(row['k'])\n",
    "   \n",
    "    global output_file\n",
    "    output_file = open(tex_dir + 'tables.tex', 'w+')\n",
    "    output_file.write('\\documentclass{article}\\n')\n",
    "    output_file.write('\\\\usepackage{geometry} \\n ' + \n",
    "                         '\\geometry{ \\n ' + \n",
    "                         'a4paper, \\n ' + \n",
    "                         'total={170mm,257mm}, \\n ' + \n",
    "                         'left=10mm,  \\n ' + \n",
    "                         'top=10mm,  \\n ' + \n",
    "                             '} \\n ')\n",
    "    output_file.write('\\\\usepackage{booktabs}\\n')\n",
    "    output_file.write('\\\\usepackage{graphicx}\\n')\n",
    "    output_file.write('\\\\begin{document}\\n')\n",
    "    output_file.write('\\\\noindent\\n')\n",
    "    \n",
    "    global fixed\n",
    "    \n",
    "\n",
    "    ######### Analysis of Initialization-strategies - Edits ################\n",
    "    fixed = {'randomness' : [False],\n",
    "                'sortPaths' : [True],\n",
    "                'maxIterations' : [0, 5, inf_iterations]}\n",
    "    exploring = ['graph', 'maxIterations', 'initialization']\n",
    "    res = 'edits_mean'\n",
    "    input_df = prepare('full', fixed)\n",
    "    initTableCnt(input_df, False)\n",
    "    initTableCnt(input_df, True)\n",
    "    fixed = {'randomness' : [False],\n",
    "                'sortPaths' : [True],\n",
    "                'maxIterations' : [0, inf_iterations]}\n",
    "    input_df = prepare('full', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    getOverview(input_df, exploring, res, True, True, True)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    percentualPlot(input_df, exploring, res)\n",
    "    percentualOptimumPlot(input_df, exploring[1:], res)\n",
    "    \n",
    "    ######### Analysis of Initialization-strategies - Dfference to optimum ################\n",
    "    fixed = {'randomness' : [False],\n",
    "                'sortPaths' : [True],\n",
    "                'maxIterations' : [0, inf_iterations]}\n",
    "    exploring = ['graph', 'maxIterations', 'initialization']\n",
    "    res = 'optimum_delta_percentual'\n",
    "    input_df = prepare('full', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "\n",
    "    \n",
    "    ######### Analysis of Initialization-strategies - usedIterations ################\n",
    "    fixed = {'randomness' : [False],\n",
    "                'sortPaths' : [True],\n",
    "                'maxIterations' : [inf_iterations]}\n",
    "    exploring = ['graph', 'initialization']\n",
    "    res = 'usedIterations_mean'\n",
    "    input_df = prepare('full', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    getOverview(input_df, exploring, res, True, True, False)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    scatterPlot(input_df, exploring, res)\n",
    "    \n",
    "    ######### Analysis of Initialization-strategies - runningTime ################\n",
    "    df_name = 'full'\n",
    "    fixed = {'randomness' : [False],\n",
    "                'sortPaths' : [True],\n",
    "                'maxIterations' : [0]}\n",
    "    exploring = ['graph', 'initialization']\n",
    "    res = 'time_mean'\n",
    "    input_df = prepare('full', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    getOverview(input_df, exploring, res, True, True, False)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    \n",
    "    ######### Analysis of sortPaths - edits ################\n",
    "    fixed = {'randomness' : [False],\n",
    "                'maxIterations' : [0, inf_iterations],\n",
    "                'initialization' : ['random_insert', 'asc_degree_insert']}\n",
    "    exploring = ['graph', 'maxIterations', 'initialization', 'sortPaths']\n",
    "    res = 'edits_mean'\n",
    "    input_df = prepare('full', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    getOverview(input_df, exploring, res, True, True, True)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    percentualPlot(input_df, exploring, res)\n",
    "    \n",
    "    ######### Analysis of randomness - edits ################\n",
    "    fixed = {'sortPaths' : [True],\n",
    "                'maxIterations' : [0, inf_iterations],\n",
    "                'initialization' : ['asc_degree_insert']}\n",
    "    exploring = ['graph', 'maxIterations', 'randomness']\n",
    "    res = 'edits_mean'\n",
    "    input_df = prepare('full', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    getOverview(input_df, exploring, res, True, True, True)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    \n",
    "    ######### Analysis of randomness - plateauBound ################\n",
    "    fixed = {'initialization' : ['editing', 'asc_degree_insert']}\n",
    "    exploring = ['graph', 'sortPaths', 'initialization', 'plateauSize']\n",
    "    res = 'edits_mean'\n",
    "    input_df = prepare('plateauBound', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    getOverview(input_df, exploring, res, True, True, True)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    \n",
    "    fixed = {'plateauSize' : [100], 'sortPaths' : [True]}\n",
    "    exploring = ['graph', 'plateauSize', 'initialization']\n",
    "    res = 'actualPlateau_mean'\n",
    "    input_df = prepare('plateauBound', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    exploring = ['plateauSize', 'initialization']\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    scatterPlot(input_df, ['graph', 'initialization'], res)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ######### Analysis of Convergence ################\n",
    "    df_name = 'full'\n",
    "    fixed = {'randomness' : [False],\n",
    "                'sortPaths' : [True],\n",
    "                'maxIterations' : [0, 5, inf_iterations]}\n",
    "    exploring = ['graph', 'initialization', 'maxIterations']\n",
    "    res = 'edits_mean'\n",
    "    input_df = prepare('full', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    getOverview(input_df, exploring, res, True, True, False)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    \n",
    "    \n",
    "    output_file.write('\\end{document}\\n')\n",
    "    output_file.close()\n",
    "    \n",
    "def bq():\n",
    "    ######### Analysis of Bucket queue effect ################\n",
    "    fixed = {'randomness' : [False],\n",
    "                'sortPaths' : [True],\n",
    "                'maxIterations' : [0, inf_iterations]}\n",
    "    exploring = ['graph', 'maxIterations', 'initialization']\n",
    "    res = 'bq_effect'\n",
    "    input_df = prepare('full', fixed)\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    exploring = ['maxIterations', 'initialization']\n",
    "    getOverview(input_df, exploring, res, False, False, False)\n",
    "    output_file.write('\\\\newpage \\n \\\\noindent ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addInformation(graph_set):\n",
    "    data_path = '../output/QTM_gpute2/' + graph_set + '/'\n",
    "    dfs = {}\n",
    "    #scenarios = ['full', 'plateauBound', 'withoutBucketQueue']\n",
    "    scenarios = ['full', 'plateauBound']\n",
    "    for scenario in scenarios:\n",
    "        dfs[scenario] = pd.read_csv(data_path + scenario + '.csv')\n",
    "    \n",
    "    \n",
    "    optima = {'karate' : 21, 'lesmis' : 60, 'dolphins' : 72}\n",
    "    bio_df = pd.read_csv('../input/biological/bio_data.csv')\n",
    "    for index, row in bio_df.iterrows():\n",
    "        optima[row['Graph'].split('.')[0]] = int(row['k'])\n",
    "    \n",
    "    df = dfs['full']\n",
    "    df = df.reset_index()\n",
    "    optima_column = []\n",
    "    delta_column = []\n",
    "    percentual_column = []\n",
    "    #bq_effect_column = []\n",
    "    #time_wbq_column = []\n",
    "    \n",
    "    #bq_df = dfs['withoutBucketQueue']\n",
    "    for i, row in df.iterrows():\n",
    "        graph = row['graph']\n",
    "        time = df.iloc[[i]]['time_mean'].values[0]\n",
    "        #bq_time = bq_df.iloc[[i]]['time_mean'].values[0]\n",
    "        #bq_effect_column.append(bq_time - time)\n",
    "        #time_wbq_column.append(bq_time)\n",
    "        if graph in optima:\n",
    "            optima_column.append(optima[graph])\n",
    "            delta_column.append(row['edits_mean'] - optima[graph])\n",
    "            if optima[graph] == 0:\n",
    "                percentual_column.append((row['edits_mean'] - optima[graph]))\n",
    "            else :\n",
    "                percentual_column.append((row['edits_mean'] - optima[graph]) / optima[graph])\n",
    "        else:\n",
    "            optima_column.append(np.nan)\n",
    "            delta_column.append(np.nan)\n",
    "            percentual_column.append(np.nan)\n",
    "        \n",
    "    df.insert(13, column='optimum', value=optima_column)\n",
    "    df.insert(14, column='optimum_delta', value=delta_column)\n",
    "    df.insert(15, column='optimum_delta_percentual', value=percentual_column)\n",
    "    #df.insert(16, column='time_wbq', value=time_wbq_column)\n",
    "    #df.insert(17, column='bq_effect', value=bq_effect_column)\n",
    "    dfs['full'] = df\n",
    "    \n",
    "    if (graph_set == 'biological'):\n",
    "        for(name, df) in dfs.items():\n",
    "            df['graph'] = df['graph'].apply(shorten)\n",
    "    \n",
    "    \n",
    "    dfs['full'].to_csv(data_path +  '/full.csv')\n",
    "    dfs['plateauBound'].to_csv(data_path + '/plateauBound.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-70b51dc49b10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maddInformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-756861c0c1dd>\u001b[0m in \u001b[0;36maddInformation\u001b[0;34m(graph_set)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'graph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m#bq_time = bq_df.iloc[[i]]['time_mean'].values[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#bq_effect_column.append(bq_time - time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/index.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_mean'"
     ]
    }
   ],
   "source": [
    "addInformation('facebook')\n",
    "plot('facebook')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
